{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Report\n",
    "\n",
    "## Github URL\n",
    "\n",
    "https://github.com/MichaelSandilands/UCDPA_Michael_Sandilands\n",
    "\n",
    "## Abstract\n",
    "\n",
    "**Which customers are similar?**\n",
    "\n",
    "The aim of this project is to segment the customers in a database using features from the products they purchase. \n",
    "\n",
    "The project can be broken into five different parts:\n",
    "\n",
    "### 1. Data Collection\n",
    "\n",
    "A simple script to download the data from a github repository and store in locally. \n",
    "\n",
    "### 2. Data Merging\n",
    "\n",
    "The data is stored in a relational database. There are eleven different tables in total and these have to be explored to uncover the columns that are pertinent to our business question and merged for analysis.\n",
    "\n",
    "### 3. Exploratory Data Analysis\n",
    "\n",
    "Now that we have the columns pertinent to the business question, we need to determine if they will be useful.\n",
    "\n",
    "### 4. Data Preparation & Feature Engineering\n",
    "\n",
    "Now we know what data will be useful it has to be prepared for the clustering. This involves:\n",
    "- Placing the data in a customer/feature matrix. \n",
    "- Transform the data to approximate a normal distribution.\n",
    "- Standardize the data so that large values don't dominate the analysis.\n",
    "- Dimension reduction techniques. \n",
    "\n",
    "### 5. Clustering and Insights\n",
    "\n",
    "The prepared data is then clustered using the K-Means algorithm. A range of clusters are fitted to each feature and inertia plots are used to find the optimal number of clusters. Insights are then drawn from these clusters.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "I wanted a project that is a good approximation of an actual business workflow. For this I needed to find a relational database. The Chinook database fits the criteria for this assignment plus goals of mine beyond this coarse. \n",
    "\n",
    "I don't plan on stopping at clustering, I'm going to attempt to classify which customers are going to repurchase in the next 90 days. Not very well as there is such a small sample of data, which is why I stuck to clustering for this assignment. Such a small dataset would make it challenging to do things such as hyperparameter tuning as, with such a small sample, it is very unlikely to generalize well to never before seen data no matter what models or hyperparameters I use. \n",
    "\n",
    "But the goal is not to practice hyperparameter tuning or cross validation. The goal is to practice dashboard creation. I imagine a dashboard which displays insights into which customers are likely to repurchase in the next 90 days in conjunction with the clustering insights, will look very good on my github portfolio. \n",
    "\n",
    "I also utilized this project to enhance my visualization capabilities, creating my own personal theme for plotting.\n",
    "\n",
    "## Dataset\n",
    "\n",
    "The Chinook database is a fairly small cross-section of data, containing only 59 unique customers, but think of this as a sample to test a workflow that can be scaled to larger data in the future. The Chinook database includes tables for artists, albums, tracks, invoices, and customers.\n",
    "\n",
    "A source for the data base can be found at [this github repository](https://github.com/lerocha/chinook-database). I'll be using the SQLite version of the database. \n",
    "\n",
    "## Implementation Process\n",
    "\n",
    "### Data Collection\n",
    "\n",
    "https://github.com/MichaelSandilands/UCDPA_Michael_Sandilands/tree/master/01_Data_Download\n",
    "\n",
    "Steps:\n",
    "- Retrieve the database using the `requests` module.\n",
    "- Save the database locally.\n",
    "\n",
    "### Data Merging\n",
    "\n",
    "https://github.com/MichaelSandilands/UCDPA_Michael_Sandilands/tree/master/02_Data_Merging\n",
    "\n",
    "Steps:\n",
    "- Import data from database using the `sqlalchemy` module & a `dictionary`.\n",
    "- Explore database tables using an `iterator`.\n",
    "- `merge` the pertinent columns from these tables into a single `DataFrame`.\n",
    "- Drop the unnecessary columns using `regex`. \n",
    "- Reorder columns using `list comprehension` and the unpacking `*` operator.\n",
    "- Write merged `DataFrame` locally to `CSV`\n",
    "\n",
    "### Exploratory Data Analysis\n",
    "\n",
    "https://github.com/MichaelSandilands/UCDPA_Michael_Sandilands/tree/master/03_Exploratory_Data_Analysis\n",
    "\n",
    "Steps: \n",
    "- Import data using `pd.read_csv()`.\n",
    "- Check for `duplicated rows`.\n",
    "- Inspect `data types` & `missing values`.\n",
    "- Explore the numeric data using `summary statistics` and a created `function` to visualize `histograms`.\n",
    "- Explore the categorical data using `summary statistics` on the `counts` for each column.\n",
    "- Visualize the relationship between customer id and Milliseconds using `boxplots`.\n",
    "\n",
    "### Data Preparation & Feature Engineering\n",
    "\n",
    "https://github.com/MichaelSandilands/UCDPA_Michael_Sandilands/tree/master/04_Data_Preparation_and_Feature_Engineering\n",
    "\n",
    "Steps:\n",
    "- Import data using `pd.read_csv()`.\n",
    "- Create a `function` to place the data in a customer/category frequency matrix. This function:\n",
    "  - `Counts` each category.\n",
    "  - `Pivots` these `counts` from a long format into a wide format.\n",
    "  - Replaces `missing values` using the `fillna()` function.\n",
    "- Process the `transformations` and `dimension reduction` on these customer/category frequency matrices to get them ready for clustering.\n",
    "- Compute the `quantiles` for the numeric column and place these into a customer/quantile matrix.\n",
    "- Process the `transformations` on the customer/quantile matrix to get it ready for clustering.\n",
    "- Save the matrices to `CSV` files and save the processed matrices to `pickle` files.\n",
    "\n",
    "### Clustering and Insights\n",
    "\n",
    "https://github.com/MichaelSandilands/UCDPA_Michael_Sandilands/tree/master/05_Clustering_and_Insights\n",
    "\n",
    "Steps:\n",
    "- Import the `CSV` files and `pickle` files.\n",
    "- `Fit` and visualize the optimal number of `K-Means clusters` using a created `function` which displays the `Inertia` vs `Number of Clusters`.\n",
    "- `Fit` the optimal number of clusters to their respective data.\n",
    "- `Visualize` the clusters using the `UMAP` projections.\n",
    "- Use the `Clusters` to gain insights.\n",
    "  - Visualize the top 10 Genres for each Genre cluster.\n",
    "  - Use this plot to generate insights about what customers are similar in terms of Genre.\n",
    "  - Explore why some Genres are ubiquitous across clusters using a created `function`, (this function can also be used to visualize the artist column).\n",
    "  - Visualize the top 30 Artists for each Artist cluster.\n",
    "  - Use this plot to generate insights about what customers are similar in terms of Artist.\n",
    "  - Visualize boxplots of Milliseconds vs Quantile partitioned by Milliseconds cluster.\n",
    "  - Use this plot to generate insights about Milliseconds clusters across quantiles.\n",
    "\n",
    "## Results & Insights\n",
    "\n",
    "I use UMAP Projections to generate insights for all the columns of interest. \n",
    "\n",
    "I use the top 10 Genres per Genre Cluster to generate insights which customers are similar in terms of Genre.\n",
    "\n",
    "I use the top 30 Artists per Artist Cluster to generate insights which customers are similar in terms of Artist.\n",
    "\n",
    "I use boxplots of Milliseconds vs Quantile partitioned by Milliseconds cluster to generate insights about the Milliseconds clusters across quantiles.\n",
    "\n",
    "### Genre Name\n",
    "\n",
    "#### Genre UMAP Projections\n",
    "\n",
    "![Customer/Genre UMAP Projections and K-Means Clusters](./00_Images/customer_genre_umap.png)\n",
    "\n",
    "Besides showing us how the k-means algorithm segmented our data, this UMAP projection graph really lets us see which customers are most similar to each other. Take for example the 5 orange clusters on the left hand side of the plot, customer id 16, 55, 36, 35 and 27. These customers are well separated from any other points and are tightly clustered together. This suggests that these customers have very similar taste in genres.\n",
    "\n",
    "#### Top 10 Genres Per Cluster\n",
    "\n",
    "![Top 10 Genres Per Cluster](./00_Images/genre_insights.png)\n",
    "\n",
    "This plot shows the top 10 genres for each cluster. This plot will help us to know which genres to market to each customer. \n",
    "\n",
    "For example: \n",
    "- All Clusters like \"Rock\", \"Latin\", \"Metal\" and \"Alternative & Punk\". \"Rock\" is the most frequent in every cluster.\n",
    "- Cluster 0: Likes \"Rock\" most of all, followed by \"Latin\", then \"Metal\" then \"Alternative & Punk\" then \"Jazz\".\n",
    "- Cluster 1: Is the only cluster that breaks the top 4 trend of \"Rock\", \"Latin\", \"Metal\" and \"Alternative & Punk\", having a preference for \"Blues\" over \"Alternative & Punk\". \"Metal\" also out performs \"Latin\".\n",
    "- Cluster 2: Has the highest frequency for the \"Latin\" genre out of all the customers. \"Metal\" and \"Alternative & Puck\" are neck and neck.\n",
    "- Cluster 3: \"Rock\" performs the best followed by \"Latin\". \"Alternative & Punk\" outperforms \"Metal\". \n",
    "- Cluster 4: Has a very skewed distribution. Clearly having a preference for \"Rock\". \"Alternative & Puck\" is neck and neck with \"Latin\" and both outperform \"Metal\"\n",
    "\n",
    "### Artist Name\n",
    "\n",
    "#### Artist UMAP Projections\n",
    "\n",
    "![Customer/Artist UMAP Projections and K-Means Clusters](./00_Images/customer_artist_umap.png)\n",
    "\n",
    "The UMAP projections and K-Means clusters for the artist name variable. Unfortunately we have some overlap between clusters. This is likely due to there being more dimensions than we are able to visualize.\n",
    "\n",
    "#### Top 30 Artists Per Cluster\n",
    "\n",
    "![Top 30 Artists Per Cluster](./00_Images/artist_insights.png)\n",
    "\n",
    "Here we have the top 30 Artists for each cluster. This plot will help us to know which Artists to market to each customer. \n",
    "\n",
    "For example: \n",
    "- Cluster 0 has no major stand out artists. Top Artists include: \"Red Hot Chili Peppers\", \"Led Zeppelin\", \"Creedence Clearwater Revival\", and \"U2\".\n",
    "- Cluster 1 has some major stand out artists, \"Iron Maiden\", \"U2\" and \"Pearl Jam\" are clear favorites for this cluster.\n",
    "- Cluster 2 has some mild stand out artists, \"U2\", \"Led Zeppelin\" and \"Lost\" are some favorites among this cluster.\n",
    "- Cluster 3 has \"Metallica\" as it's stand out favorite. Other top artists include: \"Faith No More\", \"Foo Fighters\", \"Titas\" and \"Iron Maiden\".\n",
    "- Cluster 4 has a major stand out favorite in \"Iron Maiden\". Other top artists include: \"Deep Purple\", \"Led Zeppelin\", \"Faith No More\" and \"Metallica\".\n",
    "\n",
    "#### Milliseconds UMAP Projections\n",
    "\n",
    "![Customer/Artist UMAP Projections and K-Means Clusters](./00_Images/customer_milliseconds_umap.png)\n",
    "\n",
    "The UMAP projections and K-Means clusters for the Milliseconds variable. We can use this plot to see which customers are most similar to each other in terms of duration.\n",
    "\n",
    "#### Milliseconds (Log10) vs Quantile Partitioned by Milliseconds Cluster\n",
    "\n",
    "![Milliseconds (Log10) vs Quantile Partitioned by Milliseconds Cluster](./00_Images/milliseconds_insights.png)\n",
    "\n",
    "This plot shows how our Milliseconds features have been clustered. \n",
    "\n",
    "- Cluster 2 prefers longer duration of songs.\n",
    "- Cluster 1 prefers shorter duration of songs.\n",
    "- Cluster 0 rest in between cluster 1 & cluster 2.\n",
    "\n",
    "# References\n",
    "\n",
    "Chinook Database: https://github.com/lerocha/chinook-database\n",
    "\n",
    "sqlalchemy: https://www.sqlalchemy.org\n",
    "\n",
    "plotnine: https://plotnine.readthedocs.io/en/stable/\n",
    "\n",
    "Clustering Concepts: https://developers.google.com/machine-learning/clustering\n",
    "\n",
    "UMAP: https://umap-learn.readthedocs.io/en/latest/"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ee8c2b7036826e7dd5f7faf147445d826b4bf3f01be59f8a004bf2aeb2590613"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('venv1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
